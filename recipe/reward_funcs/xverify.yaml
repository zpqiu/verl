# config.yaml
applications:
- args:
    llm_configs:
        - model_loading_config:
            model_id: IAAR-Shanghai/xVerify-0.5B-I
            model_source: IAAR-Shanghai/xVerify-8B-I
          engine_kwargs:
            gpu_memory_utilization: 0.92
            enable_prefix_caching: true
          deployment_config:
            autoscaling_config:
                min_replicas: 4
                max_replicas: 4
  import_path: ray.serve.llm:build_openai_app
  name: llm_app
  route_prefix: "/"